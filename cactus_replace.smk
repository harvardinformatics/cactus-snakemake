#############################################################################
# Pipeline for replacing a genome in a HAL file:
# https://github.com/ComparativeGenomicsToolkit/cactus/blob/master/doc/cactus-update-prepare.md#replacing-a-genome
#
# Created April 2025
# Gregg Thomas
#############################################################################

import sys
import os
import re
import logging
import subprocess

import lib.cactuslib as CACTUSLIB
import lib.updatelib as UPDATELIB

from functools import partial

#############################################################################
# System setup

config_flag = config.get("display", False);
version_flag = config.get("version", False);
info_flag = config.get("info", False);
debug = config.get("debug", False);
#debug = True;
# A hacky way to get some custom command line arguments for the pipeline
# These just control preprocessing flags that stop the pipeline early anyways

MAIN, DRY_RUN, OUTPUT_DIR, LOG_DIR, TMPDIR, LOG_LEVEL, LOG_VERBOSITY = CACTUSLIB.pipelineSetup(config, sys.argv, version_flag, info_flag, config_flag, debug, workflow);
# Setup the pipeline, including the output directory, log directory, and tmp directory

CLOG = logging.getLogger('cactuslib')
# Setup logging if debugging

getRuleResources = partial(CACTUSLIB.getResources, config)
# This maps the function to get rule resources from the config file
# so we don't have to pass config each time we call it

#############################################################################
# Cactus setup

USE_GPU = config["use_gpu"]
# Whether to use GPU or CPU cactus

cactus_image_path, cactus_gpu_image_path = CACTUSLIB.parseCactusPath(config["cactus_path"], USE_GPU, MAIN);
# Parse the cactus path from the config file

CACTUS_PATH = ["singularity", "exec", "--cleanenv", cactus_image_path]
CACTUS_PATH_TMP = ["singularity", "exec", "--cleanenv", "--bind", TMPDIR + ":/tmp", cactus_image_path]

CACTUS_GPU_PATH = ["singularity", "exec", "--nv", "--cleanenv", cactus_gpu_image_path]
CACTUS_GPU_PATH_TMP = ["singularity", "exec", "--nv", "--cleanenv", "--bind", TMPDIR + ":/tmp", cactus_gpu_image_path]
# The path to the cactus image with and without a tmpdir binding

#############################################################################
# Input files and output paths

INPUT_FILE = os.path.abspath(config["input_file"]);
if not os.path.isfile(INPUT_FILE):
    CLOG.error(f"Could not find input file at {INPUT_FILE}");
    sys.exit(1);
else:
    if MAIN:
        CLOG.info(f"Input file found at {INPUT_FILE}");
# The cactus input file used to generate the config file with cactus-prepare

INPUT_HAL = config["input_hal"];
MAF_REFERENCE = config["maf_reference"];
FINAL_PREFIX = config["final_prefix"]
# Various input parameters

if config["overwrite_original_hal"]:
    HAL_TO_EDIT = os.path.abspath(INPUT_HAL);
else:
    HAL_TO_EDIT = os.path.join(OUTPUT_DIR, f"{FINAL_PREFIX}.hal");
# The output HAL file generated by the pipeline

OUTPUT_MAF = os.path.join(OUTPUT_DIR, f"{FINAL_PREFIX}.{MAF_REFERENCE}.maf.gz");
OUTPUT_MAF_NODUPES = os.path.join(OUTPUT_DIR, f"{FINAL_PREFIX}.{MAF_REFERENCE}.nodupes.maf.gz");
# The output MAF files generated by the pipeline

if MAIN:
    CLOG.info(f"Output HAL file will be at {HAL_TO_EDIT}");
    CLOG.info(f"Reference genome for MAF file will be {MAF_REFERENCE}");
    CLOG.info(f"Output MAF file will be at {OUTPUT_MAF}");
# The final output files for the pipeline

UPDATE_TYPE = "replace";
REPLACE  = config["replace"];
# The update type and genome to replace

CHILD = "";
ANCNAME = "";
TOP_BL = "";
# Placeholders for the other required arguments for cactus-update-prepare for the branch replacement pipeline
# (since they share the runCactusUpdatePrepare() function)

#############################################################################
# cactus-prepare

if MAIN:
    SEQ_FILES = UPDATELIB.runCactusUpdatePrepare(INPUT_HAL, INPUT_FILE, CACTUS_PATH, OUTPUT_DIR, UPDATE_TYPE, USE_GPU, LOG_DIR, DRY_RUN, REPLACE, CHILD, ANCNAME, TOP_BL);
# if DRY_RUN:
#     CACTUS_FILE = os.path.join("/tmp/", "cactus-update-smk-dryrun", os.path.basename(INPUT_FILE));
# else:
CACTUS_FILE = os.path.join(OUTPUT_DIR, os.path.basename(INPUT_FILE));
# Run cactus-prepare to generate the cactus input file with ancestral nodes and labeled tree

#############################################################################
# Reading files

NEW_GENOME_FILE, ANCNAME = UPDATELIB.getGenomesToAddReplace(os.path.join(OUTPUT_DIR, "seq_file.out"), REPLACE);
# Get the genomes to add from the input file

CLOG.debug(f"New genome file will be at : {NEW_GENOME_FILE}");
CLOG.debug(f"Parsed ancestor of sub-tree: {ANCNAME}");
# The new genome file generated by the pipeline

####################

if LOG_LEVEL == "debug":
    CLOG.debug("EXITING BEFORE RULES. DEBUG MODE.");
    sys.exit(0);
# Exit before running rules if in debug mode

#############################################################################
# Final rule - rule that depends on final expected output file and initiates all
# the other rules

localrules: all

rule all:
    input:
        OUTPUT_MAF,
        OUTPUT_MAF_NODUPES
## Rule all specifies the final output files expected

# #############################################################################
# # Pipeline rules

rule preprocess:
    input:
        seq_in  = os.path.join(OUTPUT_DIR, "seq_file.in"),
        seq_out = os.path.join(OUTPUT_DIR, "seq_file.out"),
    output:
        replacement_fa = NEW_GENOME_FILE
    params:
        path = CACTUS_PATH_TMP,
        replace_name = REPLACE,
        job_tmp_dir = os.path.join("/tmp", f"{REPLACE}-preprocess"), # This is the tmp dir in the container, which is bound to the host tmp dir
        host_tmp_dir = os.path.join(TMPDIR, f"{REPLACE}-preprocess"), # This is the tmp dir for the host system, which is bound to /tmp in the singularity container
        rule_name = "preprocess"
    log:
        job_log = os.path.join(LOG_DIR, f"{os.path.basename(NEW_GENOME_FILE)}.preprocess.log")
    resources:
        **getRuleResources("preprocess")
    run:
        cmd = params.path + [
            "cactus-preprocess",
            params.job_tmp_dir,
            input.seq_in,
            input.seq_out,
            "--inputNames", params.replace_name,
            "--logInfo",
            "--retryCount", "0",
            "--maxCores", str(resources.cpus_per_task),
            
        ];

        # if params.gpu_opt:
        #     cmd.append("--gpu");

        CACTUSLIB.runCommand(cmd, params.host_tmp_dir, log.job_log, params.rule_name, params.replace_name)
        # When not requesting all CPU on a node: toil.batchSystems.abstractBatchSystem.InsufficientSystemResources: The job LastzRepeatMaskJob is requesting 64.0 cores, more than the maximum of 32 cores that SingleMachineBatchSystem was configured with, or enforced by --maxCores.Scale is set to 1.0.
## This rule runs cactus-preprocess for every genome (tip in the tree), which does some masking
## Runtimes for turtles range from 8 to 15 minutes with the above resoureces

####################

rule blast:
    input:
        replacement_fa = NEW_GENOME_FILE
    output:
        paf_file = os.path.join(OUTPUT_DIR, f"{ANCNAME}.paf")
    params:
        path = CACTUS_GPU_PATH_TMP, # Note that if USE_GPU is False, this will be the same as CACTUS_PATH_TMP
        cactus_file = os.path.join(OUTPUT_DIR, "seq_file.out"),
        node = ANCNAME,
        job_tmp_dir = os.path.join("/tmp", f"{ANCNAME}-blast"), # This is the tmp dir in the container, which is bound to the host tmp dir
        host_tmp_dir = os.path.join(TMPDIR, f"{ANCNAME}-blast"), # This is the tmp dir for the host system, which is bound to /tmp in the singularity container
        gpu_opt = USE_GPU,
        gpu_num = config['rule_resources']['blast']['gpus'],
        rule_name = "blast"
    log:
        job_log = os.path.join(LOG_DIR, f"{ANCNAME}.blast.log")
    resources:
        **getRuleResources("blast"),
        slurm_extra = f"'--gres=gpu:{config['rule_resources']['blast']['gpus']}'" if USE_GPU else ""
    run:
        cmd = params.path + [
            "cactus-blast",
            params.job_tmp_dir,
            params.cactus_file,
            output.paf_file,
            "--root", params.node,
            "--logInfo",
            "--retryCount", "0",
            "--includeRoot",
            "--lastzCores", str(resources.cpus_per_task)
        ];

        if params.gpu_opt:
            cmd += ["--gpu", str(params.gpu_num)];

        CACTUSLIB.runCommand(cmd, params.host_tmp_dir, log.job_log, params.rule_name, params.node)
# This rule runs cactus-blast for every internal node
# Runtimes for turtles range from 1 to 10 hours with the above resources

####################

rule align:
    input:
        paf_file = os.path.join(OUTPUT_DIR, f"{ANCNAME}.paf")
    output:
        hal_file = os.path.join(OUTPUT_DIR, f"{ANCNAME}.hal")
    params:
        path = CACTUS_PATH_TMP,
        cactus_file = os.path.join(OUTPUT_DIR, "seq_file.out"),
        node = ANCNAME,
        job_tmp_dir = os.path.join("/tmp", f"{ANCNAME}-align"), # This is the tmp dir in the container, which is bound to the host tmp dir
        host_tmp_dir = os.path.join(TMPDIR, f"{ANCNAME}-align"), # This is the tmp dir for the host system, which is bound to /tmp in the singularity container
        work_dir = TMPDIR,
        rule_name = "align"
    log:
        job_log = os.path.join(LOG_DIR, f"{ANCNAME}.align.log")
    resources:
        **getRuleResources("align")
    run:
        cmd = params.path + [
            "cactus-align",
            params.job_tmp_dir,
            params.cactus_file,
            input.paf_file,
            output.hal_file,
            "--root", params.node,
            "--logInfo",
            "--retryCount", "0",
            "--includeRoot",
            "--maxCores", str(resources.cpus_per_task),
        ];

        CACTUSLIB.runCommand(cmd, params.host_tmp_dir, log.job_log, params.rule_name, params.node)
## This rule runs cactus-align for every internal node
## Runtimes for turtles range from 4 to 16 hours with the above resources

####################

rule copy_or_get_hal:
    input:
        input_hal = INPUT_HAL
    output:
        copy_or_get_hal_stamp = os.path.join(LOG_DIR, "copy-hal.stamp")
    params:
        overwrite_original_hal = config["overwrite_original_hal"],
        hal_to_edit = HAL_TO_EDIT,
        rule_name = "copy_or_get_hal"
    log:
        job_log = os.path.join(LOG_DIR, "copy-hal.log")
    resources:
        **getRuleResources("copy_or_get_hal")   
    run:
        if not params.overwrite_original_hal:
            # If the hal file is not being overwritten, copy the input hal file to the output directory
            cmd = ["cp", input.input_hal, params.hal_to_edit];
            CACTUSLIB.runCommand(cmd, None, log.job_log, params.rule_name)

            with open(output.copy_or_get_hal_stamp, "w") as f:
                f.write(f"original hal copied: {params.hal_to_edit}");
        else:
            with open(output.copy_or_get_hal_stamp, "w") as f:
                f.write(f"using original hal: {params.hal_to_edit}");
## Copying the root .hal file here, since failures in the subsequent rules
## would mean the blast/align steps have to be re-run for that node, but this means a little extra
## storage is required

####################

rule remove_genome:
    input:
        copy_or_get_hal_stamp = os.path.join(LOG_DIR, "copy-hal.stamp")
    output:
        remove_genome_stamp = os.path.join(LOG_DIR, "remove-genome.stamp")
    params:
        path = CACTUS_PATH,
        hal_to_edit = HAL_TO_EDIT,
        node = REPLACE,
        rule_name = "remove_genome"
    log:
        job_log = os.path.join(LOG_DIR, "remove-genome.log")
    resources:
        **getRuleResources("remove_genome")
    run:
        cmd = params.path + [
            "halRemoveGenome",
            params.hal_to_edit,
            params.node,
        ];

        CACTUSLIB.runCommand(cmd, None, log.job_log, params.rule_name)

        with open(output.remove_genome_stamp, "w") as f:
            f.write("done");

####################

rule replace_genome:
    input:
        anc_hal = os.path.join(OUTPUT_DIR, f"{ANCNAME}.hal"), 
        remove_genome_stamp = os.path.join(LOG_DIR, "remove-genome.stamp")
    output:
        replace_genome_stamp = os.path.join(LOG_DIR, "replace-genome.stamp")
    params:
        path = CACTUS_PATH,
        hal_to_edit = HAL_TO_EDIT,
        anc_node = ANCNAME,
        rule_name = "replace_genome"
    log:
        job_log = os.path.join(LOG_DIR, "replace-genome.log")
    resources:
        **getRuleResources("replace_genome")
    run:
        cmd = params.path + [
            "halReplaceGenome",
            "--bottomAlignmentFile", input.anc_hal,
            "--topAlignmentFile", params.hal_to_edit,
            params.hal_to_edit,
            params.anc_node,
            "--hdf5InMemory"
        ];

        CACTUSLIB.runCommand(cmd, None, log.job_log, params.rule_name)

        with open(output.replace_genome_stamp, "w") as f:
            f.write("done");
## This rule runs halReplaceGenome to replace the genome in the hal file

####################

rule maf:
    input:
        replace_genome_stamp = os.path.join(LOG_DIR, "replace-genome.stamp")
    output:
        final_maf = OUTPUT_MAF,
        final_maf_nodupes = OUTPUT_MAF_NODUPES
    params:
        path = CACTUS_PATH_TMP,
        hal_to_edit = HAL_TO_EDIT,
        ref_genome = MAF_REFERENCE,
        chunk_size = 500000, # 500kb
        host_tmp_dir = os.path.join(TMPDIR, "maf"),
        job_tmp_dir = os.path.join("/tmp", "maf"),
        rule_name = "maf"
    log:
        job_log = os.path.join(LOG_DIR, "maf.log")
    resources:
        **getRuleResources("maf")
    run:
        cmd = params.path + [
            "cactus-hal2maf",
            params.job_tmp_dir,
            params.hal_to_edit,
            output.final_maf,
            "--refGenome", params.ref_genome,
            "--chunkSize", str(params.chunk_size),
            "--batchCount", str(resources.cpus_per_task),
            "--filterGapCausingDupes"
        ];

        CACTUSLIB.runCommand(cmd, params.job_tmp_dir, log.job_log, params.rule_name);

        cmd = params.path + [
            "cactus-hal2maf",
            params.job_tmp_dir,
            params.hal_to_edit,
            output.final_maf_nodupes,
            "--refGenome", params.ref_genome,
            "--chunkSize", str(params.chunk_size),
            "--batchCount", str(resources.cpus_per_task),
            "--filterGapCausingDupes",
            "--dupeMode", "single"
        ];

        CACTUSLIB.runCommand(cmd, params.host_tmp_dir, log.job_log, params.rule_name, fmode="a+");

#############################################################################

#############################################################################
# Pipeline for adding a new genome to a HAL file generated by Cactus using
# the add to branch method:
# https://github.com/ComparativeGenomicsToolkit/cactus/blob/master/doc/updating-alignments.md
# https://github.com/ComparativeGenomicsToolkit/cactus/blob/master/doc/cactus-update-prepare.md
#
# Created April 2025
# Gregg Thomas
#############################################################################

import sys
import os
import re
import logging
import subprocess

import lib.cactuslib as CACTUSLIB
from lib.cactuslib import spacedOut as SO
import lib.updatelib as UPDATELIB

from functools import partial

#############################################################################
# System setup

config_flag = config.get("display", False);
version_flag = config.get("version", False);
info_flag = config.get("info", False);
debug = config.get("debug", False);
prep_only = config.get("prep", False);
#debug = True;
# A hacky way to get some custom command line arguments for the pipeline
# These just control preprocessing flags that stop the pipeline early anyways

pad = config.get("pad", 50);
debug_pad = pad - 1;
# The padding for some of the log messages

MAIN, DRY_RUN, OUTPUT_DIR, LOG_DIR, TMPDIR, LOG_LEVEL, LOG_VERBOSITY, TOP_LEVEL_EXECUTOR = CACTUSLIB.pipelineSetup(config, sys.argv, version_flag, info_flag, config_flag, debug, workflow, pad);
# Setup the pipeline, including the output directory, log directory, and tmp directory

CLOG = logging.getLogger('cactuslib')
# Setup logging if debugging

getRuleResources = partial(CACTUSLIB.getResources, config, TOP_LEVEL_EXECUTOR)
# This maps the function to get rule resources from the config file
# so we don't have to pass config each time we call it

#############################################################################
# Cactus setup

USE_GPU = config["use_gpu"]
# Whether to use GPU or CPU cactus

CACTUS_PATH, CACTUS_PATH_TMP, VERSION_TAG = CACTUSLIB.parseCactusPath(config["cactus_path"], USE_GPU, MAIN, TMPDIR, pad);
# Parse the cactus path from the config file

KEG_PATCH_FILE = None
if USE_GPU:
    # Normalize tag (strip leading "v"), grab the major version before the first dot,
    # ensure it's numeric, and check if it's less than 3.
    tag_major = str(VERSION_TAG).lstrip('v').split('.', 1)[0]
    if tag_major.isdigit() and int(tag_major) < 3:
        KEG_PATCH_FILE = CACTUSLIB.downloadKegPatch(OUTPUT_DIR, MAIN, VERSION_TAG)
# Download the KEG patch file if using GPU cactus, and set the path to it

#############################################################################
# Input files and output paths

GENOME_NAME = config["new_genome_name"];
GENOME_FASTA = config["new_genome_fasta"];
GENOME_EXT = os.path.splitext(GENOME_FASTA)[1][1:];
# The name of the new genome to be added to the tree

NEW_GENOME_FILE = os.path.join(OUTPUT_DIR, f"{GENOME_NAME}.{GENOME_EXT}");
# The new genome file to be added to the tree

NEW_BL = config["new_branch_length"];
# The new branch length for the new genome

INPUT_FILE = os.path.join(OUTPUT_DIR, "cactus-replace-input.txt");
if MAIN:
    UPDATELIB.createUpdateInputFile(INPUT_FILE, GENOME_NAME, GENOME_FASTA, NEW_BL, OUTPUT_DIR, pad);
# The cactus input file used by cactus-update-prepare

INPUT_HAL = config["input_hal"];
MAF_REFERENCE = config["maf_reference"];
FINAL_PREFIX = config["final_prefix"]
# Other various input parameters

if config["overwrite_original_hal"]:
    HAL_TO_EDIT = os.path.abspath(INPUT_HAL);
else:
    HAL_TO_EDIT = os.path.join(OUTPUT_DIR, f"{FINAL_PREFIX}.hal");
# The output HAL file generated by the pipeline

OUTPUT_MAF = os.path.join(OUTPUT_DIR, f"{FINAL_PREFIX}.{MAF_REFERENCE}.maf.gz");
OUTPUT_MAF_NODUPES = os.path.join(OUTPUT_DIR, f"{FINAL_PREFIX}.{MAF_REFERENCE}.nodupes.maf.gz");
# The output MAF files generated by the pipeline

if MAIN:
    CLOG.info(SO(f"Output HAL file will be at", pad) +f"{HAL_TO_EDIT}");
    CLOG.info(SO(f"Reference genome for MAF file will be", pad) +f"{MAF_REFERENCE}");
    CLOG.info(SO(f"Output MAF file will be at", pad) +f"{OUTPUT_MAF}");
# The final output files for the pipeline

UPDATE_TYPE = "branch";
PARENT  = config["parent_node"];
CHILD   = config["child_node"];
ANCNAME = config["new_anc_node"];
#ORIG_BL = config["orig_branch_length"]; # NOTE: Could read tree to get this
TOP_BL  = config["top_branch_length"];
if not TOP_BL:
    TOP_BL = 1.0;
# The update type and the parent and child genomes for the update

#############################################################################
# cactus-prepare

if MAIN:
    UPDATELIB.runCactusUpdatePrepare(INPUT_HAL, INPUT_FILE, CACTUS_PATH, OUTPUT_DIR, UPDATE_TYPE, USE_GPU, LOG_DIR, DRY_RUN, PARENT, CHILD, ANCNAME, TOP_BL);
# if DRY_RUN:
#     CACTUS_FILE = os.path.join("/tmp/", "cactus-update-smk-dryrun", os.path.basename(INPUT_FILE));
# else:
#CACTUS_FILE = os.path.join(OUTPUT_DIR, os.path.basename(INPUT_FILE));
# Run cactus-prepare to generate the cactus input file with ancestral nodes and labeled tree

CACTUS_SEQ_INPUT = os.path.join(OUTPUT_DIR, "seq_file.in");
CACTUS_SEQ_OUTPUT = os.path.join(OUTPUT_DIR, "seq_file.out");
# The input and output sequence files generated by cactus-update-prepare

ORIG_BL = UPDATELIB.getOrigBranchLength(CACTUS_SEQ_OUTPUT, CHILD, ANCNAME, TOP_BL);

#############################################################################
# Reading files

#GENOME_NAME, GENOME_EXT = UPDATELIB.getGenomesToAddUpdate(INPUT_FILE);
# Get the genomes to add from the input file

rounds = { ANCNAME : { "name" : ANCNAME, 
                            "blast-input" : NEW_GENOME_FILE,
                            "blast-output" : os.path.join(OUTPUT_DIR, ANCNAME + ".paf"), 
                            "align-output" : os.path.join(OUTPUT_DIR, ANCNAME + ".hal"),
                            "convert-output" : os.path.join(OUTPUT_DIR, ANCNAME + ".fa.gz") },
            PARENT : { "name" : PARENT, 
                        "blast-input" : [os.path.join(OUTPUT_DIR, ANCNAME + ".hal"), os.path.join(OUTPUT_DIR, ANCNAME + ".fa")], 
                        # This technically also needs the other descendant seq file, but it should always be there
                        # Would be better to parse the tree for these, but not necessary at this point...

                        "blast-output" : os.path.join(OUTPUT_DIR, PARENT + ".paf"),
                        "align-output" : os.path.join(OUTPUT_DIR, PARENT + ".hal"),
                        "convert-output" : os.path.join(OUTPUT_DIR, PARENT + ".fa") }, 
        };

####################

if MAIN:
    CLOG.info(SO("New genome name", pad) + GENOME_NAME);
    CLOG.info(SO("Input genome fasta", pad) + GENOME_FASTA);
    CLOG.info(SO("New genome branch length", pad) + str(NEW_BL));
    CLOG.info(SO("New ancestral node", pad) + ANCNAME);
    CLOG.info(SO("Parent node of new ancestral node", pad) + PARENT);
    CLOG.info(SO("Child node of new ancestral node", pad) + CHILD);
    CLOG.info(SO(f"Original branch length of the {CHILD}-{PARENT} branch", pad) + str(ORIG_BL));
    CLOG.info(SO(f"Branch length of the new {ANCNAME}-{PARENT} branch", pad) + str(TOP_BL));
    CLOG.info(SO(f"Branch length of the new {CHILD}-{ANCNAME} branch", pad) + str(ORIG_BL - TOP_BL));

if LOG_LEVEL == "debug":
    for node in rounds:
        CLOG.debug(f"Node: {node}");
        for key in rounds[node]:
            CLOG.debug(SO(f"{key}", pad) + f"{rounds[node][key]}");
    CLOG.debug("===================================================================================");
    # The dictionary for storing information and file paths for the nodes in the tree:

####################

if LOG_LEVEL == "debug":
    CLOG.debug("EXITING BEFORE RULES. DEBUG MODE.");
    sys.exit(0);
# Exit before running rules if in debug mode

if prep_only:
    CLOG.info("PREP ONLY FLAG SET. EXITING.");
    sys.exit(0);
# Exit before running rules if prep only flag is set

#############################################################################
# Final rule - rule that depends on final expected output file and initiates all
# the other rules

# wildcard_constraints:
#     node = f"^(?!{FINAL_PREFIX}$).*"

localrules: all

rule all:
    input:
        final_maf = OUTPUT_MAF,
        final_maf_nodupes = OUTPUT_MAF_NODUPES
## Rule all specifies the final output files expected

# #############################################################################
# # Pipeline rules

rule preprocess:
    input:
        seq_in  = CACTUS_SEQ_INPUT,
        seq_out = CACTUS_SEQ_OUTPUT,
    output:
        NEW_GENOME_FILE
    params:
        path = CACTUS_PATH,
        genome_name = GENOME_NAME,
        job_tmp_dir = os.path.join("/tmp", f"{GENOME_NAME}-preprocess"), # This is the tmp dir in the container, which is bound to the host tmp dir
        host_tmp_dir = os.path.join(TMPDIR, f"{GENOME_NAME}-preprocess"), # This is the tmp dir for the host system, which is bound to /tmp in the singularity container
        rule_name = "preprocess"
    log:
        job_log = os.path.join(LOG_DIR, f"{GENOME_NAME}.{GENOME_EXT}.preprocess.log")
    resources:
        **getRuleResources("preprocess")
    run:
        cmd = params.path + [
            "cactus-preprocess",
            params.job_tmp_dir,
            input.seq_in,
            input.seq_out,
            "--inputNames", params.genome_name,
            "--logInfo",
            "--retryCount", "0",
            "--maxCores", str(resources.cpus_per_task)
        ];

        CACTUSLIB.runCommand(cmd, params.host_tmp_dir, log.job_log, params.rule_name, params.genome_name)
        # When not requesting all CPU on a node: toil.batchSystems.abstractBatchSystem.InsufficientSystemResources: The job LastzRepeatMaskJob is requesting 64.0 cores, more than the maximum of 32 cores that SingleMachineBatchSystem was configured with, or enforced by --maxCores.Scale is set to 1.0.
## This rule runs cactus-preprocess for every genome (tip in the tree), which does some masking
## Runtimes for turtles range from 8 to 15 minutes with the above resoureces

####################

rule blast:
    input:
        lambda wildcards: rounds[wildcards.node]['blast-input']
        #lambda wildcards: [ rounds[name]['blast-input'] for name in rounds if name == wildcards.node ]
        #expand(os.path.join(OUTPUT_DIR, "{genome_name}.{genome_ext}"), genome_name=GENOME_NAMES, genome_ext=GENOME_EXTS, zip=True)
    output:
        paf_file = os.path.join(OUTPUT_DIR, "{node}.paf")
    params:
        path = CACTUS_PATH_TMP,
        seq_out = CACTUS_SEQ_OUTPUT,
        node = "{node}",
        job_tmp_dir = os.path.join("/tmp", "{node}-blast"), # This is the tmp dir in the container, which is bound to the host tmp dir
        host_tmp_dir = os.path.join(TMPDIR, "{node}-blast"), # This is the tmp dir for the host system, which is bound to /tmp in the singularity container
        gpu_opt = USE_GPU,
        gpu_num = config['rule_resources']['blast']['gpus'],
        rule_name = "blast"
    log:
        job_log = os.path.join(LOG_DIR, "{node}.blast.log")
    resources:
        **getRuleResources("blast"),
        slurm_extra = f"'--gres=gpu:{config['rule_resources']['blast']['gpus']}'" if USE_GPU else ""
    run:
        cmd = params.path + [
            "cactus-blast",
            params.job_tmp_dir,
            params.seq_out,
            output.paf_file,
            "--root", params.node,
            "--logInfo",
            "--retryCount", "0",
            "--lastzCores", str(resources.cpus_per_task)
        ];

        if params.gpu_opt:
            cmd += ["--gpu", str(params.gpu_num)];

        CACTUSLIB.runCommand(cmd, params.host_tmp_dir, log.job_log, params.rule_name, wildcards.node)
## This rule runs cactus-blast for every internal node
## Runtimes for turtles range from 1 to 10 hours with the above resources

# ####################

rule align:
    input:
        paf_file = lambda wildcards: rounds[wildcards.node]['blast-output']
        #paf_file = lambda wildcards: [ rounds[name]['blast-output'] for name in rounds if name == wildcards.node ]
        #paf_file = os.path.join(OUTPUT_DIR, ANCNAME + ".paf")
        #seq_files = lambda wildcards: [ os.path.join(OUTPUT_DIR, input_file) for input_file in internals[wildcards.internal_node]['desc-seqs'] ]
    output:
        hal_file = os.path.join(OUTPUT_DIR, "{node}.hal")
    params:
        path = CACTUS_PATH_TMP,
        cactus_file = CACTUS_SEQ_OUTPUT,
        node = "{node}",
        keg_patch_file = KEG_PATCH_FILE,
        job_tmp_dir = os.path.join("/tmp", "{node}-align"), # This is the tmp dir in the container, which is bound to the host tmp dir
        host_tmp_dir = os.path.join(TMPDIR, "{node}-align"), # This is the tmp dir for the host system, which is bound to /tmp in the singularity container
        work_dir = TMPDIR,
        rule_name = "align"
    log:
        job_log = os.path.join(LOG_DIR, "{node}.align.log")
    resources:
        **getRuleResources("align")
    run:
        cmd = params.path + [
            "cactus-align",
            params.job_tmp_dir,
            params.cactus_file,
            input.paf_file,
            output.hal_file,
            "--root", params.node,
            "--logInfo",
            "--retryCount", "0",
            "--maxCores", str(resources.cpus_per_task),
        ];

        if params.keg_patch_file:
            cmd += ["--configFile", params.keg_patch_file];

        CACTUSLIB.runCommand(cmd, params.host_tmp_dir, log.job_log, params.rule_name, wildcards.node)
## This rule runs cactus-align for every internal node
## Runtimes for turtles range from 4 to 16 hours with the above resources

####################

rule convert:
    input:
        hal_file = lambda wildcards: rounds[wildcards.node]['align-output']
        #lambda wildcards: [ os.path.join(output_dir, input_file) for input_file in internals[wildcards.internal_node]['hal-inputs'] ][0]
    output:
        fa_file = os.path.join(OUTPUT_DIR, "{node}.fa")
    params:
        path = CACTUS_PATH,
        node = "{node}",
        rule_name = "convert"
    log:
        job_log = os.path.join(LOG_DIR, "{node}.convert.log")
    resources:
        **getRuleResources("convert")
    run:
        cmd = params.path + [
            "hal2fasta",
            input.hal_file,
            params.node,
            "--outFaPath", output.fa_file,
            "--hdf5InMemory"
        ];

        CACTUSLIB.runCommand(cmd, None, log.job_log, params.rule_name, params.node)
## This rule runs hal2fasta to convert .hal files for each internal node to .fasta files
## Runtime for turtles is only about 30 seconds per node

####################

rule copy_or_get_hal:
    input:
        input_hal = INPUT_HAL
    output:
        stamp = os.path.join(LOG_DIR, "copy-hal.stamp")
    params:
        overwrite_original_hal = config["overwrite_original_hal"],
        hal_to_edit = HAL_TO_EDIT,
        rule_name = "copy_or_get_hal"
    log:
        job_log = os.path.join(LOG_DIR, "copy-hal.log")
    resources:
        **getRuleResources("copy_or_get_hal")    
    run:
        if not params.overwrite_original_hal:
            # If the hal file is not being overwritten, copy the input hal file to the output directory
            cmd = ["cp", input.input_hal, params.hal_to_edit];
            CACTUSLIB.runCommand(cmd, None, log.job_log, params.rule_name)

            with open(output.stamp, "w") as f:
                f.write(f"original hal copied: {params.hal_to_edit}");
        else:
            with open(output.stamp, "w") as f:
                f.write(f"using original hal: {params.hal_to_edit}");
## Copying the root .hal file here, since failures in the subsequent rules
## would mean the blast/align steps have to be re-run for that node, but this means a little extra
## storage is required

# ####################

rule add_to_branch:
    input:
        expand(os.path.join(OUTPUT_DIR, "{node}.fa"), node=rounds.keys()),
        copy_hal_stamp = os.path.join(LOG_DIR, "copy-hal.stamp")
    output:
        stamp = os.path.join(LOG_DIR, "add_to_branch.stamp")
    params:
        path = CACTUS_PATH,
        hal_to_edit = HAL_TO_EDIT,
        anc_hal = os.path.join(OUTPUT_DIR, ANCNAME + ".hal"),
        parent_hal = os.path.join(OUTPUT_DIR, PARENT + ".hal"),
        parent = PARENT,
        anc_name = ANCNAME,
        child = CHILD,
        genome_name = GENOME_NAME,
        top_bl = TOP_BL,
        orig_bl = ORIG_BL,
        host_tmp_dir = os.path.join(TMPDIR, "add-to-branch"),
        rule_name = "add_to_branch"
    log:
        job_log = os.path.join(LOG_DIR, "hal-add-to-branch.log")
    resources:
        **getRuleResources("add_to_branch")
    run:
        cmd = params.path + [
            "halAddToBranch",
            params.hal_to_edit,
            params.anc_hal,
            params.parent_hal,
            params.parent,
            params.anc_name,
            params.child,
            params.genome_name
        ]

        if params.top_bl:
            cmd += [ str(params.top_bl) ];
        else:
            cmd += [ "1.0" ];
        if params.orig_bl:
            cmd += [ str(params.orig_bl) ];
        else:
            cmd += [ "1.0" ];

        cmd += ["--hdf5InMemory"];

        CACTUSLIB.runCommand(cmd, params.host_tmp_dir, log.job_log, params.rule_name)

        with open(output.stamp, "w") as f:
            f.write("done");
        # This is just a stamp file to indicate that the rule has completed

    ## This rule runs halAddToBranch to add the new genome to the tree
####################

rule maf:
    input:
        stamp = os.path.join(LOG_DIR, "add_to_branch.stamp")
    output:
        final_maf = OUTPUT_MAF,
        final_maf_nodupes = OUTPUT_MAF_NODUPES
    params:
        path = CACTUS_PATH_TMP,
        hal_to_edit = HAL_TO_EDIT,
        ref_genome = MAF_REFERENCE,
        chunk_size = 500000, # 500kb
        host_tmp_dir = os.path.join(TMPDIR, "maf"),
        job_tmp_dir = os.path.join("/tmp", "maf"),
        rule_name = "maf"
    log:
        job_log = os.path.join(LOG_DIR, "maf.log")
    resources:
        **getRuleResources("maf")
    run:
        cmd = params.path + [
            "cactus-hal2maf",
            params.job_tmp_dir,
            params.hal_to_edit,
            output.final_maf,
            "--refGenome", params.ref_genome,
            "--chunkSize", str(params.chunk_size),
            "--batchCount", str(resources.cpus_per_task),
            "--filterGapCausingDupes"
        ];

        CACTUSLIB.runCommand(cmd, params.job_tmp_dir, log.job_log, params.rule_name);

        cmd = params.path + [
            "cactus-hal2maf",
            params.job_tmp_dir,
            params.hal_to_edit,
            output.final_maf_nodupes,
            "--refGenome", params.ref_genome,
            "--chunkSize", str(params.chunk_size),
            "--batchCount", str(resources.cpus_per_task),
            "--filterGapCausingDupes",
            "--outType", "single"
        ];

        CACTUSLIB.runCommand(cmd, params.host_tmp_dir, log.job_log, params.rule_name, fmode="a+");

#############################################################################
